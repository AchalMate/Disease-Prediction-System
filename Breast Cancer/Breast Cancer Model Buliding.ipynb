{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report,precision_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report,precision_score,recall_score,roc_curve,auc,accuracy_score,f1_score\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata = pd.read_csv(\"Selected_Breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texture_mean\n",
      "Lower Bound = 0  Upper Bound = 0.69\n",
      "min value = 0.0  max value = 1.0\n",
      "positive Outliers 7\n",
      "==================================================\n",
      "concavity_mean\n",
      "Lower Bound = 0  Upper Bound = 0.66\n",
      "min value = 0.0  max value = 1.0\n",
      "positive Outliers 18\n",
      "==================================================\n",
      "symmetry_mean\n",
      "Lower Bound = 0.03  Upper Bound = 0.71\n",
      "min value = 0.0  max value = 1.0\n",
      "negative Outliers 1\n",
      "positive Outliers 14\n",
      "==================================================\n",
      "texture_se\n",
      "Lower Bound = 0  Upper Bound = 0.46\n",
      "min value = 0.0  max value = 1.0\n",
      "positive Outliers 20\n",
      "==================================================\n",
      "area_se\n",
      "Lower Bound = 0  Upper Bound = 0.15\n",
      "min value = 0.0  max value = 1.0000000000000002\n",
      "positive Outliers 65\n",
      "==================================================\n",
      "fractal_dimension_se\n",
      "Lower Bound = 0  Upper Bound = 0.25\n",
      "min value = 0.0  max value = 1.0\n",
      "positive Outliers 28\n",
      "==================================================\n",
      "diagnosis\n",
      "Lower Bound = 0  Upper Bound = 2.5\n",
      "min value = 0  max value = 1\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in finaldata.columns:\n",
    "    Q1,Q3 = np.quantile(finaldata[i],[0.25,0.75])\n",
    "    IQR = Q3-Q1\n",
    "    lower_bound = Q1 - (1.5*IQR)\n",
    "    if lower_bound < 0:  # as in whole dataset there is no -ve value hence we set lowerbound to 0\n",
    "        lower_bound=0\n",
    "    upper_bound = Q3 + (1.5*IQR)\n",
    "    print(i)\n",
    "    print('Lower Bound =',np.round(lower_bound,2),' Upper Bound =',np.round(upper_bound,2))\n",
    "    print('min value =',finaldata[i].min(), ' max value =', finaldata[i].max())\n",
    "\n",
    "    if finaldata[i].min() < lower_bound:\n",
    "        print('negative Outliers',len(finaldata[(finaldata[i]<lower_bound)]))\n",
    "    \n",
    "    if finaldata[i].max() > upper_bound:\n",
    "        print('positive Outliers', len(finaldata[(finaldata[i]>upper_bound)]))  \n",
    "        \n",
    "   \n",
    "        \n",
    "       \n",
    "    \n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report,precision_score,recall_score,roc_curve,auc,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= finaldata.drop('diagnosis',axis =1)\n",
    "y= finaldata['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 6), (114, 6), (455,), (114,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "logistic_model = LogisticRegression()\n",
    "svc_linear = SVC(kernel='linear',probability=True)\n",
    "svc_rbf = SVC(kernel='rbf',probability=True)\n",
    "navieBayes_gaussian = GaussianNB()\n",
    "DT = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "adb_classifier = AdaBoostClassifier()\n",
    "ExtraTreesClassifier= ExtraTreesClassifier()\n",
    "GradientBoostingClassifier = GradientBoostingClassifier()\n",
    "xgb_classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_name 0.9098901098901099 0.9210526315789473\n",
      "svc linear Kernal 0.9186813186813186 0.9298245614035088\n",
      "svc rbf Kernal 0.9582417582417583 0.9473684210526315\n",
      "navieBayes_gaussian 0.9120879120879121 0.9385964912280702\n",
      "Decision Tree Classifier 1.0 0.9122807017543859\n",
      "K Neighbors Classifier 0.9538461538461539 0.9473684210526315\n",
      "Random Forest Classifier 1.0 0.9824561403508771\n",
      "Ada Boost Classifier 0.9934065934065934 0.9385964912280702\n",
      "ExtraTreesClassifier 1.0 0.9824561403508771\n",
      "Gradient Boosting Classifier 1.0 0.9473684210526315\n",
      "[14:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 1.0 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "Algorithm = []\n",
    "Training = []\n",
    "Testing = []\n",
    "# 1. Logistic Regression\n",
    "logistic_name = 'logistic_name'\n",
    "Algorithm.append(logistic_name)\n",
    "logistic_model.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred1=logistic_model.predict(X_train)\n",
    "log_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred1)\n",
    "Training.append(log_Accuracy_train)\n",
    "\n",
    "y_test_pred1=logistic_model.predict(X_test)\n",
    "log_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred1)\n",
    "Testing.append(log_Accuracy_test)\n",
    "print(logistic_name,log_Accuracy_train,log_Accuracy_test)\n",
    "\n",
    "#*********************************************************************\n",
    "#2 . SVC  Linear \n",
    "svc_linear_name = 'svc linear Kernal'\n",
    "svc_linear.fit(X_train,y_train)\n",
    "Algorithm.append(svc_linear_name)\n",
    "\n",
    "y_train_pred2=svc_linear.predict(X_train)\n",
    "svc_linear_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred2)\n",
    "Training.append(svc_linear_Accuracy_train)\n",
    "\n",
    "y_test_pred2=svc_linear.predict(X_test)\n",
    "svc_linear_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred2)\n",
    "Testing.append(svc_linear_Accuracy_test)\n",
    "print(svc_linear_name,svc_linear_Accuracy_train,svc_linear_Accuracy_test)\n",
    "\n",
    "#*******************************************************\n",
    "# 3. svc_rbf \n",
    "svc_rbf_name = 'svc rbf Kernal'\n",
    "svc_rbf.fit(X_train,y_train)\n",
    "Algorithm.append(svc_rbf_name)\n",
    "\n",
    "y_train_pred3=svc_rbf.predict(X_train)\n",
    "svc_rbf_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred3)\n",
    "Training.append(svc_rbf_Accuracy_train)\n",
    "\n",
    "y_test_pred3=svc_rbf.predict(X_test)\n",
    "svc_rbf_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred3)\n",
    "Testing.append(svc_rbf_Accuracy_test)\n",
    "print(svc_rbf_name,svc_rbf_Accuracy_train,svc_rbf_Accuracy_test)\n",
    "#*****************************************************************************\n",
    "# 4 navieBayes_gaussian \n",
    "navieBayes_gaussian_name = 'navieBayes_gaussian'\n",
    "navieBayes_gaussian.fit(X_train,y_train)\n",
    "Algorithm.append(navieBayes_gaussian_name)\n",
    "\n",
    "y_train_pred4=navieBayes_gaussian.predict(X_train)\n",
    "navieBayes_gaussian_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred4)\n",
    "Training.append(navieBayes_gaussian_Accuracy_train)\n",
    "\n",
    "y_test_pred4=navieBayes_gaussian.predict(X_test)\n",
    "navieBayes_gaussian_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred4)\n",
    "Testing.append(navieBayes_gaussian_Accuracy_test)\n",
    "\n",
    "print(navieBayes_gaussian_name,navieBayes_gaussian_Accuracy_train,navieBayes_gaussian_Accuracy_test)\n",
    "#**************************************************************************\n",
    "# 5 DecisionTreeClassifier \n",
    "DT_name  = 'Decision Tree Classifier'\n",
    "DT.fit(X_train,y_train)\n",
    "Algorithm.append(DT_name)\n",
    "        \n",
    "y_train_pred5=DT.predict(X_train)\n",
    "DT_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred5)\n",
    "Training.append(DT_Accuracy_train)\n",
    "        \n",
    "y_test_pred5=DT.predict(X_test)\n",
    "DT_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred5)\n",
    "Testing.append(DT_Accuracy_test)\n",
    "print(DT_name,DT_Accuracy_train,DT_Accuracy_test)\n",
    "       \n",
    "#*******************************************************************************\n",
    "# 6 knn \n",
    "knn_name = 'K Neighbors Classifier'\n",
    "knn.fit(X_train,y_train)\n",
    "Algorithm.append(knn_name)\n",
    "\n",
    "y_train_pred6=knn.predict(X_train)\n",
    "knn_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred6)\n",
    "Training.append(knn_Accuracy_train)\n",
    "\n",
    "y_test_pred6=knn.predict(X_test)\n",
    "knn_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred6)\n",
    "Testing.append(knn_Accuracy_test)\n",
    "print(knn_name,knn_Accuracy_train,knn_Accuracy_test)\n",
    "#*************************************************************************\n",
    "#7 RandomForestClassifier\n",
    "random_forest_name = 'Random Forest Classifier'\n",
    "random_forest.fit(X_train,y_train)\n",
    "Algorithm.append(random_forest_name)\n",
    "\n",
    "y_train_pred7=random_forest.predict(X_train)\n",
    "random_forest_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred7)\n",
    "Training.append(random_forest_Accuracy_train)\n",
    "\n",
    "y_test_pred7=random_forest.predict(X_test)\n",
    "random_forest_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred7)\n",
    "Testing.append(random_forest_Accuracy_test)\n",
    "\n",
    "print(random_forest_name,random_forest_Accuracy_train,random_forest_Accuracy_test)\n",
    "#********************************************************************************\n",
    "# 8 adb_classifier = AdaBoostClassifier()\n",
    "adb_classifier_name = 'Ada Boost Classifier'\n",
    "adb_classifier.fit(X_train,y_train)\n",
    "Algorithm.append(adb_classifier_name)\n",
    "\n",
    "y_train_pred8=adb_classifier.predict(X_train)\n",
    "adb_classifier_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred8)\n",
    "Training.append(adb_classifier_Accuracy_train)\n",
    "\n",
    "y_test_pred8=adb_classifier.predict(X_test)\n",
    "adb_classifier_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred8)\n",
    "Testing.append(adb_classifier_Accuracy_test)\n",
    "print(adb_classifier_name,adb_classifier_Accuracy_train,adb_classifier_Accuracy_test)\n",
    "#******************************************************************************\n",
    "#9 ExtraTreesClassifier= ExtraTreesClassifier() \n",
    "ExtraTreesClassifier_name = 'ExtraTreesClassifier'\n",
    "ExtraTreesClassifier.fit(X_train,y_train)\n",
    "Algorithm.append(ExtraTreesClassifier_name)\n",
    "\n",
    "y_train_pred9=ExtraTreesClassifier.predict(X_train)\n",
    "ExtraTreesClassifier_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred9)\n",
    "Training.append(ExtraTreesClassifier_Accuracy_train)\n",
    "y_test_pred9=ExtraTreesClassifier.predict(X_test)\n",
    "ExtraTreesClassifier_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred9)\n",
    "Testing.append(ExtraTreesClassifier_Accuracy_test)\n",
    "print(ExtraTreesClassifier_name,ExtraTreesClassifier_Accuracy_train,ExtraTreesClassifier_Accuracy_test)\n",
    "#********************************************************************************\n",
    "# 10 GradientBoostingClassifier = GradientBoostingClassifier()\n",
    "\n",
    "GradientBoostingClassifier_name = 'Gradient Boosting Classifier'\n",
    "GradientBoostingClassifier.fit(X_train,y_train)\n",
    "Algorithm.append(GradientBoostingClassifier_name)\n",
    "\n",
    "y_train_pred10=GradientBoostingClassifier.predict(X_train)\n",
    "GradientBoostingClassifier_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred10)\n",
    "Training.append(GradientBoostingClassifier_Accuracy_train)\n",
    "\n",
    "y_test_pred10=GradientBoostingClassifier.predict(X_test)\n",
    "GradientBoostingClassifier_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred10)\n",
    "Testing.append(GradientBoostingClassifier_Accuracy_test)\n",
    "print(GradientBoostingClassifier_name,GradientBoostingClassifier_Accuracy_train,GradientBoostingClassifier_Accuracy_test)\n",
    "#******************************************************************************\n",
    "#11 xgb_classifier = XGBClassifier()\n",
    "xgb_classifier_name = 'XGBClassifier'\n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "Algorithm.append(xgb_classifier_name)\n",
    "\n",
    "y_train_pred11=xgb_classifier.predict(X_train)\n",
    "xgb_classifier_Accuracy_train=metrics.accuracy_score(y_train,y_train_pred11)\n",
    "Training.append(xgb_classifier_Accuracy_train)\n",
    "\n",
    "y_test_pred11=xgb_classifier.predict(X_test)\n",
    "xgb_classifier_Accuracy_test=metrics.accuracy_score(y_test,y_test_pred11)\n",
    "Testing.append(xgb_classifier_Accuracy_test)\n",
    "\n",
    "print(xgb_classifier_name,xgb_classifier_Accuracy_train,xgb_classifier_Accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Accuracy={'Algorithm':Algorithm,'Accuracy':Training}\n",
    "Testing_Accuracy={'Algorithm':Algorithm,'Accuracy':Testing}\n",
    "Training_Accuracy = pd.DataFrame(Training_Accuracy)\n",
    "Testing_Accuracy  = pd.DataFrame(Testing_Accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.993407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc rbf Kernal</td>\n",
       "      <td>0.958242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc linear Kernal</td>\n",
       "      <td>0.918681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>navieBayes_gaussian</td>\n",
       "      <td>0.912088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_name</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Algorithm  Accuracy\n",
       "4       Decision Tree Classifier  1.000000\n",
       "6       Random Forest Classifier  1.000000\n",
       "8           ExtraTreesClassifier  1.000000\n",
       "9   Gradient Boosting Classifier  1.000000\n",
       "10                 XGBClassifier  1.000000\n",
       "7           Ada Boost Classifier  0.993407\n",
       "2                 svc rbf Kernal  0.958242\n",
       "5         K Neighbors Classifier  0.953846\n",
       "1              svc linear Kernal  0.918681\n",
       "3            navieBayes_gaussian  0.912088\n",
       "0                  logistic_name  0.909890"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Accuracy.sort_values('Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc rbf Kernal</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>navieBayes_gaussian</td>\n",
       "      <td>0.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc linear Kernal</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_name</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Algorithm  Accuracy\n",
       "6       Random Forest Classifier  0.982456\n",
       "8           ExtraTreesClassifier  0.982456\n",
       "10                 XGBClassifier  0.973684\n",
       "2                 svc rbf Kernal  0.947368\n",
       "5         K Neighbors Classifier  0.947368\n",
       "9   Gradient Boosting Classifier  0.947368\n",
       "3            navieBayes_gaussian  0.938596\n",
       "7           Ada Boost Classifier  0.938596\n",
       "1              svc linear Kernal  0.929825\n",
       "0                  logistic_name  0.921053\n",
       "4       Decision Tree Classifier  0.912281"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_Accuracy.sort_values('Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization : GridSearch with Cross Validation for tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning = []\n",
    "Training_tuning = []\n",
    "Testing_tuning = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "Wall time: 5.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A parameter grid for Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'penalty':['l1', 'l2'],'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "'class_weight' :[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "'solver' : ['liblinear', 'saga'] }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "    \n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the knn to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Train the model using the training sets \n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_clf_test = clf.predict(X_test)\n",
    "y_pred_clf_train = clf.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model training :  0.9604395604395605\n",
      "Accuracy of Logistic Regression model testing :  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_clf_test =  metrics.accuracy_score(y_test, y_pred_clf_test) \n",
    "acc_clf_train =  metrics.accuracy_score(y_train, y_pred_clf_train) \n",
    "\n",
    "print( 'Accuracy of Logistic Regression model training : ', acc_clf_train )\n",
    "print( 'Accuracy of Logistic Regression model testing : ', acc_clf_test )\n",
    "\n",
    "roc_clf_train =metrics.roc_auc_score(y_train,y_pred_clf_train )\n",
    "roc_clf_test = metrics.roc_auc_score(y_test,y_pred_clf_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('Logistic Regression')\n",
    "Training_tuning.append(acc_clf_train)\n",
    "Testing_tuning.append(acc_clf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a Support Vector Classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = {\n",
    "  'kernel': ['linear','rbf'],\n",
    "  'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "   'class_weight' :[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "  'gamma': [0.001, 0.0001],\n",
    "    'probability':[True]\n",
    "             }\n",
    "   \n",
    "\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(svc, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "    \n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "svc = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "svc.fit(X_train,y_train)\n",
    "y_pred_svc_test = svc.predict(X_test)\n",
    "y_pred_svc_train = svc.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC model training :  0.9538461538461539\n",
      "Accuracy of SVC model testing :  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_svc_test =  metrics.accuracy_score(y_test, y_pred_svc_test)\n",
    "acc_svc_train = metrics.accuracy_score(y_train, y_pred_svc_train) \n",
    "print( 'Accuracy of SVC model training : ', acc_svc_train )\n",
    "print( 'Accuracy of SVC model testing : ', acc_svc_test )\n",
    "\n",
    "roc_svc_train =metrics.roc_auc_score(y_train,y_pred_svc_train )\n",
    "roc_svc_test = metrics.roc_auc_score(y_test,y_pred_svc_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('SVC')\n",
    "Training_tuning.append(acc_svc_train)\n",
    "Testing_tuning.append(acc_svc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 256 candidates, totalling 2560 fits\n",
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# K - Nearest Neighbors\n",
    "\n",
    "# Create a KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'n_neighbors': [3, 4, 5, 10], \n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'leaf_size' : [10, 20, 30, 50],\n",
    "              'p':[1,2]\n",
    "             }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(knn, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the knn to the best combination of parameters\n",
    "knn = grid_obj.best_estimator_\n",
    "\n",
    "# Train the model using the training sets \n",
    "knn.fit(X_train,y_train)\n",
    "y_pred_knn_test = knn.predict(X_test)\n",
    "y_pred_knn_train = knn.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN model training :  1.0\n",
      "Accuracy of KNN model testing :  0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_knn_test =  metrics.accuracy_score(y_test, y_pred_knn_test)\n",
    "acc_knn_train = metrics.accuracy_score(y_train, y_pred_knn_train)\n",
    "\n",
    "print( 'Accuracy of KNN model training : ', acc_knn_train )\n",
    "print( 'Accuracy of KNN model testing : ', acc_knn_test )\n",
    "\n",
    "roc_knn_train =metrics.roc_auc_score(y_train,y_pred_knn_train )\n",
    "roc_knn_test = metrics.roc_auc_score(y_test,y_pred_knn_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('KNeighborsClassifier')\n",
    "Training_tuning.append(acc_knn_train)\n",
    "Testing_tuning.append(acc_knn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = [{\n",
    " 'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "   \n",
    "]\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(nb, parameters,verbose=1, cv=10, n_jobs=-1,scoring= 'accuracy')\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "nb = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "nb.fit(X_train,y_train)\n",
    "y_pred_nb_test = nb.predict(X_test)\n",
    "y_pred_nb_train = nb.predict(X_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB model training :  0.9120879120879121\n",
      "Accuracy of GaussianNB model testing :  0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_nb_test = metrics.accuracy_score(y_test, y_pred_nb_test) \n",
    "acc_nb_train = metrics.accuracy_score(y_train, y_pred_nb_train) \n",
    "\n",
    "print( 'Accuracy of GaussianNB model training : ', acc_nb_train )\n",
    "print( 'Accuracy of GaussianNB model testing : ', acc_nb_test )\n",
    "\n",
    "roc_nb_train =metrics.roc_auc_score(y_train,y_pred_nb_train )\n",
    "roc_nb_test = metrics.roc_auc_score(y_test,y_pred_nb_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('GaussianNB')\n",
    "Training_tuning.append(acc_nb_train)\n",
    "Testing_tuning.append(acc_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3840 candidates, totalling 38400 fits\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DTT = DecisionTreeClassifier()\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10, 50], \n",
    "              'min_samples_split': [2, 3, 50, 100],\n",
    "              'min_samples_leaf': [1, 5, 8, 10],\n",
    "              'splitter':['best',\"random\"],\n",
    "            'random_state':[10,51,42,101]\n",
    "             }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(DTT, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose=3)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "DTT = grid_obj.best_estimator_\n",
    "\n",
    "# Train the model using the training sets \n",
    "DTT.fit(X_train,y_train)\n",
    "y_pred_DTT_test = DTT.predict(X_test)\n",
    "y_pred_DTT_train = DTT.predict(X_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier model training :  1.0\n",
      "Accuracy of DecisionTreeClassifier model testing :  0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_DTT_test = metrics.accuracy_score(y_test, y_pred_DTT_test)\n",
    "acc_DTT_train = metrics.accuracy_score(y_train, y_pred_DTT_train) \n",
    "\n",
    "print( 'Accuracy of DecisionTreeClassifier model training : ', acc_DTT_train )\n",
    "print( 'Accuracy of DecisionTreeClassifier model testing : ', acc_DTT_test )\n",
    "\n",
    "roc_DTT_train =metrics.roc_auc_score(y_train,y_pred_DTT_train )\n",
    "roc_DTT_test = metrics.roc_auc_score(y_test,y_pred_DTT_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('DecisionTreeClassifier')\n",
    "Training_tuning.append(acc_DTT_train)\n",
    "Testing_tuning.append(acc_DTT_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Forest Classifier\n",
    "\n",
    "# Import library of RandomForestClassifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'n_estimators': [4, 6, 9, 10, 15], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1, 5, 8],\n",
    "               }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the rf to the best combination of parameters\n",
    "rf = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_rf_test = rf.predict(X_test)\n",
    "y_pred_rf_train = rf.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier model training :  0.9626373626373627\n",
      "Accuracy of Random Forest Classifier model testing :  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_rf_test =  metrics.accuracy_score(y_test, y_pred_rf_test) \n",
    "acc_rf_train =  metrics.accuracy_score(y_train, y_pred_rf_train) \n",
    "\n",
    "print( 'Accuracy of Random Forest Classifier model training : ', acc_rf_train )\n",
    "print( 'Accuracy of Random Forest Classifier model testing : ', acc_rf_test )\n",
    "\n",
    "roc_rf_train =metrics.roc_auc_score(y_train,y_pred_rf_train )\n",
    "roc_rf_test = metrics.roc_auc_score(y_test,y_pred_rf_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('RandomForestClassifier')\n",
    "Training_tuning.append(acc_rf_train)\n",
    "Testing_tuning.append(acc_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = [{\n",
    "'n_estimators': [4, 6, 9, 10, 15], \n",
    "'learning_rate': [(0.97 + x / 100) for x in range(0, 8)],\n",
    "'algorithm': ['SAMME', 'SAMME.R']\n",
    "}]\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(adb, parameters,verbose=1, scoring = 'accuracy',cv=10, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "adb = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "adb.fit(X_train,y_train)\n",
    "y_pred_adb_test = adb.predict(X_test)\n",
    "y_pred_adb_train = adb.predict(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of adb model training :  0.9604395604395605\n",
      "Accuracy of adb model testing :  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "acc_adb_test =  metrics.accuracy_score(y_test, y_pred_adb_test) \n",
    "acc_adb_train =  metrics.accuracy_score(y_train, y_pred_adb_train) \n",
    "\n",
    "print( 'Accuracy of adb model training : ', acc_adb_train )\n",
    "print( 'Accuracy of adb model testing : ', acc_adb_test )\n",
    "\n",
    "roc_adb_train =metrics.roc_auc_score(y_train,y_pred_adb_train )\n",
    "roc_adb_test = metrics.roc_auc_score(y_test,y_pred_adb_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('AdaBoostClassifier')\n",
    "Training_tuning.append(acc_adb_train)\n",
    "Testing_tuning.append(acc_adb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "Accuracy of etc model training :  1.0\n",
      "Accuracy of etc model testing :  0.9824561403508771\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    # Create a ExtraTreesClassifier\n",
    "    etc = ExtraTreesClassifier()\n",
    "\n",
    "    # Hyperparameter Optimization\n",
    "    parameters = [{\n",
    "    'n_estimators': [10,20,30,50,100,200,300]}]\n",
    "    # Run the grid search\n",
    "    grid_obj = GridSearchCV(etc, parameters,verbose=1, scoring = 'accuracy',cv=10, n_jobs=-1)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    # Set the svc to the best combination of parameters\n",
    "    etc = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "    # Train the model using the training sets \n",
    "    etc.fit(X_train,y_train)\n",
    "    y_pred_etc_test = etc.predict(X_test)\n",
    "    y_pred_etc_train = etc.predict(X_train)\n",
    "    # Calculating the accuracy\n",
    "    acc_etc_test = metrics.accuracy_score(y_test, y_pred_etc_test)\n",
    "    acc_etc_train =  metrics.accuracy_score(y_train, y_pred_etc_train)\n",
    "\n",
    "    print( 'Accuracy of etc model training : ', acc_etc_train )\n",
    "    print( 'Accuracy of etc model testing : ', acc_etc_test )\n",
    "\n",
    "    roc_etc_train =metrics.roc_auc_score(y_train,y_pred_etc_train )\n",
    "    roc_etc_test = metrics.roc_auc_score(y_test,y_pred_etc_test )\n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo_tuning.append('ExtraTreesClassifier')\n",
    "Training_tuning.append(acc_etc_train)\n",
    "Testing_tuning.append(acc_etc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.externals as extjoblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "filename = 'ExtraTreesClassifier1.sav'\n",
    "joblib.dump(etc, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuning_Testing = {'Algorithm':Algo_tuning,'Accuracy':Testing_tuning}\n",
    "Tuning_Training = {'Algorithm':Algo_tuning,'Accuracy':Training_tuning}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuning_Testing = pd.DataFrame(Tuning_Testing)\n",
    "Tuning_Training = pd.DataFrame(Tuning_Training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.962637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.960440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.960440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.912088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy\n",
       "2    KNeighborsClassifier  1.000000\n",
       "4  DecisionTreeClassifier  1.000000\n",
       "7    ExtraTreesClassifier  1.000000\n",
       "5  RandomForestClassifier  0.962637\n",
       "0     Logistic Regression  0.960440\n",
       "6      AdaBoostClassifier  0.960440\n",
       "1                     SVC  0.953846\n",
       "3              GaussianNB  0.912088"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuning_Training.sort_values('Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.903509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy\n",
       "7    ExtraTreesClassifier  0.982456\n",
       "0     Logistic Regression  0.964912\n",
       "1                     SVC  0.964912\n",
       "2    KNeighborsClassifier  0.956140\n",
       "5  RandomForestClassifier  0.947368\n",
       "6      AdaBoostClassifier  0.947368\n",
       "3              GaussianNB  0.938596\n",
       "4  DecisionTreeClassifier  0.903509"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuning_Testing.sort_values('Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def XGBClassifier(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    # XGBoost classifier most required parameters\n",
    "    params={\n",
    "         \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "         \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "         \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "         \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "         \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] \n",
    "        }\n",
    "    # Randomized Search\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_classifier = XGBClassifier()\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(xgb_classifier, param_distributions=params,cv=10, scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    xgb_classifier = random_search.best_estimator_\n",
    "    # Train the model using the training sets \n",
    "    xgb_classifier.fit(X_train,y_train)\n",
    "    y_pred_xgb_classifier_test = xgb_classifier.predict(X_test)\n",
    "    y_pred_xgb_classifier_train = xgb_classifier.predict(X_train)\n",
    "    # Calculating the accuracy\n",
    "    acc_xgb_classifier_test =metrics.accuracy_score(y_test, y_pred_xgb_classifier_test)\n",
    "    acc_xgb_classifier_train =metrics.accuracy_score(y_train, y_pred_xgb_classifier_train)\n",
    "\n",
    "    print( 'Accuracy of xgb_classifier model training : ', acc_xgb_classifier_train )\n",
    "    print( 'Accuracy of xgb_classifier model testing : ', acc_xgb_classifier_test )\n",
    "\n",
    "    roc_xgb_classifier_train =metrics.roc_auc_score(y_train,y_pred_xgb_classifier_train )\n",
    "    roc_xgb_classifier_test = metrics.roc_auc_score(y_test,y_pred_xgb_classifier_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[14:47:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:47:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of xgb_classifier model training :  0.9802197802197802\n",
      "Accuracy of xgb_classifier model testing :  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "XGBClassifier(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'XGB_model1.sav'\n",
    "# joblib.dump(xgb_classifier, filename)\n",
    "\n",
    "# loaded_model = joblib.load(filename)\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true =y_test,y_pred =y_pred_xgb_classifier_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true =y_test,y_pred =y_pred_xgb_classifier_test).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_true =y_test,y_pred =y_pred_xgb_classifier_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Create a GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Accuracy of GBC model training :  0.9538461538461539\n",
      "Accuracy of GBC model testing :  0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = [{\n",
    "\"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    'n_estimators': [4, 6, 9, 10, 15], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "     'max_depth': [3,5,10,15],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'min_samples_leaf': [4, 6, 8,10],\n",
    "               'min_samples_split': [5,10,15,20],\n",
    "}]\n",
    "\n",
    "# Run the grid search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "grid_obj = RandomizedSearchCV(GBC, param_distributions=parameters, scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "GBC = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "GBC.fit(X_train,y_train)\n",
    "y_pred_GBC_classifier_test = GBC.predict(X_test)\n",
    "y_pred_GBC_classifier_train = GBC.predict(X_train)\n",
    "# Calculating the accuracy\n",
    "acc_GBC_classifier_test =  metrics.accuracy_score(y_test, y_pred_GBC_classifier_test) \n",
    "acc_GBC_classifier_train =  metrics.accuracy_score(y_train, y_pred_GBC_classifier_train)  \n",
    "\n",
    "print( 'Accuracy of GBC model training : ', acc_GBC_classifier_train )\n",
    "print( 'Accuracy of GBC model testing : ', acc_GBC_classifier_test )\n",
    "\n",
    "roc_GBC_classifier_train =metrics.roc_auc_score(y_train,y_pred_GBC_classifier_train )\n",
    "roc_GBC_classifier_test = metrics.roc_auc_score(y_test,y_pred_GBC_classifier_test )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
