{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Clean_heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis =1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size =0.8,random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((229, 10), (58, 10), (229,), (58,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-rbf</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting Classifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb classifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistics Regression</th>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-Linear</th>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbour_KNN</th>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Navie bayes</th>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Accuracy\n",
       "Decision Tree                1.000000\n",
       "Random Forest                1.000000\n",
       "SVC-rbf                      1.000000\n",
       "AdaBoost Classifier          1.000000\n",
       "GradientBoosting Classifier  1.000000\n",
       "xgb classifier               1.000000\n",
       "Logistics Regression         0.982759\n",
       "SVC-Linear                   0.982759\n",
       "KNeighbour_KNN               0.982759\n",
       "ExtraTreesClassifier         0.965517\n",
       "Navie bayes                  0.896552"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "classifiers =['Logistics Regression','Decision Tree','Random Forest', 'Navie bayes','SVC-Linear','SVC-rbf','KNeighbour_KNN','AdaBoost Classifier','GradientBoosting Classifier','xgb classifier','ExtraTreesClassifier']\n",
    "models = [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),GaussianNB(),SVC(kernel='linear',probability=True),SVC(kernel='rbf',probability=True),KNeighborsClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(), XGBClassifier(),ExtraTreesClassifier()]\n",
    "\n",
    "for i in models:\n",
    "    model = i\n",
    "    model.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(prediction,y_test))\n",
    "models_dataframe = pd.DataFrame(accuracy,index=classifiers)\n",
    "models_dataframe.columns = ['Accuracy']\n",
    "models_dataframe.sort_values(['Accuracy'],ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistics Regression</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-Linear</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-rbf</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting Classifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb classifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbour_KNN</th>\n",
       "      <td>0.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Navie bayes</th>\n",
       "      <td>0.978166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Accuracy\n",
       "Logistics Regression         1.000000\n",
       "Decision Tree                1.000000\n",
       "Random Forest                1.000000\n",
       "SVC-Linear                   1.000000\n",
       "SVC-rbf                      1.000000\n",
       "AdaBoost Classifier          1.000000\n",
       "GradientBoosting Classifier  1.000000\n",
       "xgb classifier               1.000000\n",
       "ExtraTreesClassifier         1.000000\n",
       "KNeighbour_KNN               0.986900\n",
       "Navie bayes                  0.978166"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "classifiers =['Logistics Regression','Decision Tree','Random Forest', 'Navie bayes','SVC-Linear','SVC-rbf','KNeighbour_KNN','AdaBoost Classifier','GradientBoosting Classifier','xgb classifier','ExtraTreesClassifier']\n",
    "models = [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),GaussianNB(),SVC(kernel='linear',probability=True),SVC(kernel='rbf',probability=True),KNeighborsClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(), XGBClassifier(),ExtraTreesClassifier()]\n",
    "\n",
    "for i in models:\n",
    "    model = i\n",
    "    model.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_train)\n",
    "    accuracy.append(metrics.accuracy_score(prediction,y_train))\n",
    "models_dataframe = pd.DataFrame(accuracy,index=classifiers)\n",
    "models_dataframe.columns = ['Accuracy']\n",
    "models_dataframe.sort_values(['Accuracy'],ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Logistic Regression                              \n",
      "******************************Predict on Training******************************\n",
      "\n",
      "\n",
      "Model Name = Logistic Regression\n",
      "Accuracy is = 1.0\n",
      "Precision score is = 1.0\n",
      "Recall score =  1.0\n",
      "f1 SCore score is =  1.0\n",
      "Roc_Auc score is=  1.0\n",
      "modelname- LogisticRegression()\n",
      "Accuracy is  0.9827586206896551\n",
      "Precision score is  1.0\n",
      "Recall _score is 0.9714285714285714\n",
      "f1 SCore score is  0.9855072463768115\n",
      "Roc_Auc score is 0.9857142857142858\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 1, 34)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "print(' '*30+'Logistic Regression'+' '*30)\n",
    "logistic_modelName = 'Logistic Regression'\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train,y_train)\n",
    "print('*'*30+'Predict on Training'+'*'*30+'\\n\\n')\n",
    "y_train_pred=logistic_model.predict(X_train)\n",
    "print(\"Model Name =\",logistic_modelName)\n",
    "print(\"Accuracy is =\",metrics.accuracy_score(y_train,y_train_pred))\n",
    "print(\"Precision score is =\",metrics.precision_score(y_train,y_train_pred))\n",
    "print(\"Recall score = \",metrics.recall_score(y_train,y_train_pred))\n",
    "print(\"f1 SCore score is = \",metrics.f1_score(y_train,y_train_pred))\n",
    "print(\"Roc_Auc score is= \",metrics.roc_auc_score(y_train,y_train_pred))\n",
    "\n",
    "y_test_pred=logistic_model.predict(X_test)\n",
    "Accuracy_test=metrics.accuracy_score(y_test,y_test_pred)\n",
    "precision_test=metrics.precision_score(y_test,y_test_pred)\n",
    "recall_test=metrics.recall_score(y_test,y_test_pred)\n",
    "f1_score_test=metrics.f1_score(y_test,y_test_pred)\n",
    "roc_auc_test=metrics.roc_auc_score(y_test,y_test_pred)\n",
    "print(\"modelname-\",logistic_model)\n",
    "print(\"Accuracy is \",Accuracy_test)\n",
    "print(\"Precision score is \",precision_test)\n",
    "print(\"Recall _score is\",recall_test)\n",
    "print(\"f1 SCore score is \",f1_score_test)\n",
    "print(\"Roc_Auc score is\",roc_auc_test)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_test_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '*30+'SVM with Linear Kernel'+' '*30)\n",
    "SVM_linear_modelname = 'SVM with Linear Kernel'\n",
    "from sklearn.svm import SVC\n",
    "svc_lin_model =SVC(kernel='linear' ,C = 1)\n",
    "svc_lin_model.fit(X_train,y_train)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Predict on Training'+'*'*30)\n",
    "y_train_svc_lin = svc_lin_model.predict(X_train)\n",
    "\n",
    "Accuracy_train=metrics.accuracy_score(y_train,y_train_svc_lin )\n",
    "precision_train=metrics.precision_score(y_train,y_train_svc_lin)\n",
    "recall_train=metrics.recall_score(y_train,y_train_svc_lin)\n",
    "f1_score_train=metrics.f1_score(y_train,y_train_svc_lin)\n",
    "roc_auc_train=metrics.roc_auc_score(y_train,y_train_svc_lin)\n",
    "\n",
    "print(\"Model Name =\",SVM_linear_modelname)\n",
    "print(\"Accuracy is =\",Accuracy_train)\n",
    "print(\"Precision score is =\",precision_train)\n",
    "print(\"Recall score = \",recall_train)\n",
    "print(\"f1 SCore score is = \",f1_score_train)\n",
    "print(\"Roc_Auc score is= \",roc_auc_train)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Predict on Testing'+'*'*30+'')\n",
    "y_test_svc_lin = svc_lin_model.predict(X_test)\n",
    "Accuracy_test=metrics.accuracy_score(y_test,y_test_svc_lin)\n",
    "precision_test=metrics.precision_score(y_test,y_test_svc_lin)\n",
    "recall_test=metrics.recall_score(y_test,y_test_svc_lin)\n",
    "f1_score_test=metrics.f1_score(y_test,y_test_svc_lin)\n",
    "roc_auc_test=metrics.roc_auc_score(y_test,y_test_svc_lin)\n",
    "\n",
    "print(\"Model Name =\",SVM_linear_modelname)\n",
    "print(\"Accuracy is \",Accuracy_test)\n",
    "print(\"Precision score is \",precision_test)\n",
    "print(\"Recall _score is\",recall_test)\n",
    "print(\"f1 SCore score is \",f1_score_test)\n",
    "print(\"Roc_Auc score is\",roc_auc_test)\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_test_svc_lin).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '*30+'SVM with RBF Kernel'+' '*30)\n",
    "svc_rbf_modelname = 'SVM with RBF Kernel'\n",
    "from sklearn.svm import SVC\n",
    "svc_rbf_model =SVC(kernel='rbf' ,probability=True)\n",
    "svc_rbf_model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Predict on Training'+'*'*30+'')\n",
    "y_train_svc_rbf = svc_rbf_model.predict(X_train)\n",
    "\n",
    "Accuracy_train=metrics.accuracy_score(y_train,y_train_svc_rbf)\n",
    "precision_train=metrics.precision_score(y_train,y_train_svc_rbf)\n",
    "recall_train=metrics.recall_score(y_train,y_train_svc_rbf)\n",
    "f1_score_train=metrics.f1_score(y_train,y_train_svc_rbf)\n",
    "roc_auc_train=metrics.roc_auc_score(y_train,y_train_svc_rbf)\n",
    "\n",
    "print(\"Model Name =\",svc_rbf_modelname)\n",
    "print(\"Accuracy is =\",Accuracy_train)\n",
    "print(\"Precision score is =\",precision_train)\n",
    "print(\"Recall score = \",recall_train)\n",
    "print(\"f1 SCore score is = \",f1_score_train)\n",
    "print(\"Roc_Auc score is= \",roc_auc_train)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Predict on Testing'+'*'*30+'')\n",
    "y_test_svc_rbf = svc_rbf_model.predict(X_test)\n",
    "Accuracy_test=metrics.accuracy_score(y_test,y_test_svc_rbf)\n",
    "precision_test=metrics.precision_score(y_test,y_test_svc_rbf)\n",
    "recall_test=metrics.recall_score(y_test,y_test_svc_rbf)\n",
    "f1_score_test=metrics.f1_score(y_test,y_test_svc_rbf)\n",
    "roc_auc_test=metrics.roc_auc_score(y_test,y_test_svc_rbf)\n",
    "print(\"Model Name =\",svc_rbf_modelname)\n",
    "print(\"Accuracy is \",Accuracy_test)\n",
    "print(\"Precision score is \",precision_test)\n",
    "print(\"Recall _score is\",recall_test)\n",
    "print(\"f1 SCore score is \",f1_score_test)\n",
    "print(\"Roc_Auc score is\",roc_auc_test)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_test_svc_rbf).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.externals as extjoblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Training_Accuracy = []\n",
    "Training_precision =[]\n",
    "Training_recall = []\n",
    "Training_F1_score = []\n",
    "Training_roc_auc=[]\n",
    "\n",
    "\n",
    "Testing_Accuracy = []\n",
    "Testing_precision =[]\n",
    "Testing_recall = []\n",
    "Testing_F1_score = []\n",
    "Testing_roc_auc=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 5.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 0, 35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_modelName = 'Logistic Regression'\n",
    "Name.append(logistic_modelName)\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'penalty':['l1', 'l2'],'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "'class_weight' :[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "'solver' : ['liblinear', 'saga'] }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(logistic_model, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "    \n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the knn to the best combination of parameters\n",
    "logistic_model = grid_obj.best_estimator_\n",
    "\n",
    "# Train the model using the training sets \n",
    "logistic_model.fit(X_train,y_train)\n",
    "\n",
    "###### Predict on Training ##################\n",
    "\n",
    "y_pred_log_train = logistic_model.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_log_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_log_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_log_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_log_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_log_train))\n",
    "\n",
    "###### Predict on Training ##################\n",
    "y_pred_log_test = logistic_model.predict(X_test)\n",
    "\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_log_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_log_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_log_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_log_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_log_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_log_test).ravel()\n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filename = 'heartlinear.sav'\n",
    "joblib.dump(logistic_model, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 6.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 0, 35)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create a Support Vector Classifier\n",
    "svc = SVC()\n",
    "Name.append(\"SVC\")\n",
    "# Hyperparameter Optimization\n",
    "parameters = {\n",
    "  'kernel': ['linear','rbf'],\n",
    "  'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "   'class_weight' :[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "  'gamma': [0.001, 0.0001],\n",
    "    'probability':[True]\n",
    "             }\n",
    "   \n",
    "\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(svc, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "    \n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "svc = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "### Prediction on Training ################\n",
    "y_pred_svc_train = svc.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_svc_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_svc_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_svc_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_svc_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_svc_train))\n",
    "\n",
    "\n",
    "##### Prediction on Testing #####################\n",
    "y_pred_svc_test = svc.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_svc_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_svc_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_svc_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_svc_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_svc_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_svc_test).ravel()\n",
    "tn, fp, fn, tp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filename = 'heartSVC.sav'\n",
    "joblib.dump(svc, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.K - Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 256 candidates, totalling 2560 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 7.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 2, 33)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create a KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "Name.append(\"KNN\")\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'n_neighbors': [3, 4, 5, 10], \n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'leaf_size' : [10, 20, 30, 50],\n",
    "              'p':[1,2]\n",
    "             }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(knn, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the knn to the best combination of parameters\n",
    "knn = grid_obj.best_estimator_\n",
    "\n",
    "# Train the model using the training sets \n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "##### Predicting on Training ################\n",
    "y_pred_knn_train = knn.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_knn_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_knn_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_knn_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_knn_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_knn_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_knn_test = knn.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_knn_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_knn_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_knn_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_knn_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_knn_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_knn_test).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 2.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 0, 35)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create a GaussianNB\n",
    "nb = GaussianNB()\n",
    "Name.append(\"GaussianNB\")\n",
    "# Hyperparameter Optimization\n",
    "parameters = [{\n",
    " 'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "   \n",
    "]\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(nb, parameters,verbose=1, cv=10, n_jobs=-1,scoring= 'accuracy')\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "nb = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "##### Predicting on Training ################\n",
    "y_pred_nb_train= nb.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_nb_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_nb_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_nb_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_nb_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_nb_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_nb_test = nb.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_nb_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_nb_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_nb_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_nb_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_nb_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_nb_test).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filename = 'HeartGaussianNB.sav'\n",
    "joblib.dump(nb, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3840 candidates, totalling 38400 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 1min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 0, 35)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "DTT = DecisionTreeClassifier()\n",
    "Name.append(\"DecisionTreeClassifier\")\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10, 50], \n",
    "              'min_samples_split': [2, 3, 50, 100],\n",
    "              'min_samples_leaf': [1, 5, 8, 10],\n",
    "              'splitter':['best',\"random\"],\n",
    "            'random_state':[10,51,42,101]\n",
    "             }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(DTT, parameters,cv=10,scoring= 'accuracy', n_jobs= -1, verbose=3)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "DTT = grid_obj.best_estimator_\n",
    "\n",
    "# Train the model using the training sets \n",
    "DTT.fit(X_train,y_train)\n",
    "\n",
    "##### Predicting on Training ################\n",
    "y_pred_DTT_train = DTT.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_DTT_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_DTT_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_DTT_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_DTT_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_DTT_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_DTT_test = DTT.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_DTT_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_DTT_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_DTT_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_DTT_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_DTT_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_DTT_test).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filename = 'HeartDecisionTree.sav'\n",
    "joblib.dump(DTT, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 2min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22, 1, 1, 34)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Random Forest Classifier\n",
    "Name.append(\"Random Forest Classifier\")\n",
    "# Import library of RandomForestClassifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "parameters = {'n_estimators': [4, 6, 9, 10, 15], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1, 5, 8],\n",
    "               }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf, parameters)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the rf to the best combination of parameters\n",
    "rf = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "##### Predicting on Training ################\n",
    "y_pred_rf_train = rf.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_rf_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_rf_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_rf_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_rf_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_rf_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_rf_test = rf.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_rf_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_rf_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_rf_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_rf_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_rf_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_rf_test).ravel()\n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "filename = 'HeartRandomForest.sav'\n",
    "joblib.dump(rf, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 5.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 0, 35)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create a AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier()\n",
    "Name.append(\"AdaBoostClassifier\")\n",
    "# Hyperparameter Optimization\n",
    "parameters = [{\n",
    "'n_estimators': [4, 6, 9, 10, 15], \n",
    "'learning_rate': [(0.97 + x / 100) for x in range(0, 8)],\n",
    "'algorithm': ['SAMME', 'SAMME.R']\n",
    "}]\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(adb, parameters,verbose=1, scoring = 'accuracy',cv=10, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "adb = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "adb.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "##### Predicting on Training ################\n",
    "y_pred_adb_train = adb.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_adb_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_adb_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_adb_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_adb_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_adb_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_adb_test = adb.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_adb_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_adb_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_adb_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_adb_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_adb_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_adb_test).ravel()\n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filename = 'HeartAdboost.sav'\n",
    "joblib.dump(adb, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 3.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22, 1, 1, 34)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "    # Create a ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier()\n",
    "Name.append(\"ExtraTreesClassifier\")\n",
    "    # Hyperparameter Optimization\n",
    "parameters = [{\n",
    "    'n_estimators': [10,20,30,50,100,200,300]}]\n",
    "    # Run the grid search\n",
    "grid_obj = GridSearchCV(etc, parameters,verbose=1, scoring = 'accuracy',cv=10, n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    # Set the svc to the best combination of parameters\n",
    "etc = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "    # Train the model using the training sets \n",
    "etc.fit(X_train,y_train)\n",
    "   \n",
    "   \n",
    "    \n",
    "##### Predicting on Training ################\n",
    "y_pred_etc_train = etc.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_etc_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_etc_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_etc_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_etc_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_etc_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_etc_test = etc.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test,y_pred_etc_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test,y_pred_etc_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test,y_pred_etc_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test,y_pred_etc_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test,y_pred_etc_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred_etc_test).ravel()\n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "filename = 'HeartExtratree.sav'\n",
    "joblib.dump(etc, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[17:35:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:35:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 5.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 0, 35)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# XGBoost classifier most required parameters\n",
    "params={\n",
    "         \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "         \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "         \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "         \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "         \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] \n",
    "        }\n",
    "    # Randomized Search\n",
    "from xgboost import XGBClassifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "Name.append(\"XGBoost\")\n",
    "random_search = RandomizedSearchCV(xgb_classifier, param_distributions=params,cv=10, scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "random_search.fit(X_train, y_train)\n",
    "xgb_classifier = random_search.best_estimator_\n",
    "    # Train the model using the training sets \n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "   \n",
    "   \n",
    "    \n",
    "##### Predicting on Training ################\n",
    "y_pred_xgb_classifier_train = xgb_classifier.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_xgb_classifier_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_xgb_classifier_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_xgb_classifier_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_xgb_classifier_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_xgb_classifier_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_xgb_classifier_test = xgb_classifier.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test, y_pred_xgb_classifier_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test, y_pred_xgb_classifier_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test, y_pred_xgb_classifier_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test, y_pred_xgb_classifier_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test, y_pred_xgb_classifier_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_xgb_classifier_test).ravel()\n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filename = 'Heartxgb_classifier.sav'\n",
    "joblib.dump(xgb_classifier, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "\n",
      "\n",
      "******************************Confusion Matrix******************************\n",
      "Wall time: 450 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 0, 1, 34)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create a GradientBoostingClassifier\n",
    "Name.append(\"GradientBoostingClassifier\")\n",
    "GBC = GradientBoostingClassifier()\n",
    "# Hyperparameter Optimization\n",
    "parameters = [{\n",
    "\"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    'n_estimators': [4, 6, 9, 10, 15], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "     'max_depth': [3,5,10,15],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'min_samples_leaf': [4, 6, 8,10],\n",
    "               'min_samples_split': [5,10,15,20],\n",
    "}]\n",
    "\n",
    "# Run the grid search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "grid_obj = RandomizedSearchCV(GBC, param_distributions=parameters, scoring= 'accuracy', n_jobs= -1, verbose= 3)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the svc to the best combination of parameters\n",
    "GBC = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Train the model using the training sets \n",
    "GBC.fit(X_train,y_train)\n",
    "  \n",
    "    \n",
    "##### Predicting on Training ################\n",
    "y_pred_GBC_classifier_train = GBC.predict(X_train)\n",
    "Training_Accuracy.append(metrics.accuracy_score(y_train,y_pred_GBC_classifier_train))\n",
    "Training_precision.append(metrics.precision_score(y_train,y_pred_GBC_classifier_train))\n",
    "Training_recall.append(metrics.recall_score(y_train,y_pred_GBC_classifier_train))\n",
    "Training_F1_score.append(metrics.f1_score(y_train,y_pred_GBC_classifier_train))\n",
    "Training_roc_auc.append(metrics.roc_auc_score(y_train,y_pred_GBC_classifier_train))\n",
    "\n",
    "##### Predicting on Testing ################\n",
    "y_pred_GBC_classifier_test = GBC.predict(X_test)\n",
    "Testing_Accuracy.append(metrics.accuracy_score(y_test, y_pred_GBC_classifier_test))\n",
    "Testing_precision.append(metrics.precision_score(y_test, y_pred_GBC_classifier_test))\n",
    "Testing_recall.append(metrics.recall_score(y_test, y_pred_GBC_classifier_test))\n",
    "Testing_F1_score.append(metrics.f1_score(y_test, y_pred_GBC_classifier_test))\n",
    "Testing_roc_auc.append(metrics.roc_auc_score(y_test, y_pred_GBC_classifier_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print('*'*30+'Confusion Matrix'+'*'*30+'')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_GBC_classifier_test).ravel()\n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827586206896551\n"
     ]
    }
   ],
   "source": [
    "filename = 'HeartGBC.sav'\n",
    "joblib.dump(GBC, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy': Training_Accuracy,\n",
    "        'F1_score':Training_F1_score,\n",
    "        'precision':Training_precision,\n",
    "        'Training_recall':Training_recall,\n",
    "        'Training_roc_auc':Training_roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>Training_recall</th>\n",
       "      <th>Training_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.995633</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.995283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.991266</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98374</td>\n",
       "      <td>0.991870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.943231</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.98374</td>\n",
       "      <td>0.939983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  F1_score  precision  Training_recall  \\\n",
       "Logistic Regression         1.000000  1.000000   1.000000          1.00000   \n",
       "SVC                         1.000000  1.000000   1.000000          1.00000   \n",
       "DecisionTreeClassifier      1.000000  1.000000   1.000000          1.00000   \n",
       "AdaBoostClassifier          1.000000  1.000000   1.000000          1.00000   \n",
       "ExtraTreesClassifier        1.000000  1.000000   1.000000          1.00000   \n",
       "XGBoost                     1.000000  1.000000   1.000000          1.00000   \n",
       "GradientBoostingClassifier  1.000000  1.000000   1.000000          1.00000   \n",
       "GaussianNB                  0.995633  0.995951   0.991935          1.00000   \n",
       "KNN                         0.991266  0.991803   1.000000          0.98374   \n",
       "Random Forest Classifier    0.943231  0.949020   0.916667          0.98374   \n",
       "\n",
       "                            Training_roc_auc  \n",
       "Logistic Regression                 1.000000  \n",
       "SVC                                 1.000000  \n",
       "DecisionTreeClassifier              1.000000  \n",
       "AdaBoostClassifier                  1.000000  \n",
       "ExtraTreesClassifier                1.000000  \n",
       "XGBoost                             1.000000  \n",
       "GradientBoostingClassifier          1.000000  \n",
       "GaussianNB                          0.995283  \n",
       "KNN                                 0.991870  \n",
       "Random Forest Classifier            0.939983  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dataframe = pd.DataFrame(data,index=Name)\n",
    "models_dataframe.sort_values(['Accuracy'],ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Testing = {'Accuracy': Testing_Accuracy,\n",
    "        'F1_score':Testing_F1_score,\n",
    "        'precision':Testing_precision,\n",
    "        'Training_recall':Testing_recall,\n",
    "        'Training_roc_auc':Testing_roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>Training_recall</th>\n",
       "      <th>Training_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.963975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.927950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  F1_score  precision  Training_recall  \\\n",
       "Logistic Regression         1.000000  1.000000   1.000000         1.000000   \n",
       "SVC                         1.000000  1.000000   1.000000         1.000000   \n",
       "GaussianNB                  1.000000  1.000000   1.000000         1.000000   \n",
       "DecisionTreeClassifier      1.000000  1.000000   1.000000         1.000000   \n",
       "AdaBoostClassifier          1.000000  1.000000   1.000000         1.000000   \n",
       "XGBoost                     1.000000  1.000000   1.000000         1.000000   \n",
       "GradientBoostingClassifier  1.000000  1.000000   1.000000         1.000000   \n",
       "KNN                         0.965517  0.970588   1.000000         0.942857   \n",
       "ExtraTreesClassifier        0.965517  0.971429   0.971429         0.971429   \n",
       "Random Forest Classifier    0.931034  0.942857   0.942857         0.942857   \n",
       "\n",
       "                            Training_roc_auc  \n",
       "Logistic Regression                 1.000000  \n",
       "SVC                                 1.000000  \n",
       "GaussianNB                          1.000000  \n",
       "DecisionTreeClassifier              1.000000  \n",
       "AdaBoostClassifier                  1.000000  \n",
       "XGBoost                             1.000000  \n",
       "GradientBoostingClassifier          1.000000  \n",
       "KNN                                 0.971429  \n",
       "ExtraTreesClassifier                0.963975  \n",
       "Random Forest Classifier            0.927950  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_dataframe = pd.DataFrame(data_Testing,index=Name)\n",
    "Testing_dataframe.sort_values(['Accuracy'],ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic Regression',\n",
       " 'SVC',\n",
       " 'KNN',\n",
       " 'GaussianNB',\n",
       " 'DecisionTreeClassifier',\n",
       " 'Random Forest Classifier',\n",
       " 'AdaBoostClassifier',\n",
       " 'ExtraTreesClassifier',\n",
       " 'XGBoost',\n",
       " 'GradientBoostingClassifier']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = [logistic_model,svc,knn,nb,DTT,rf,adb,etc,xgb_classifier,GBC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1000, class_weight={0: 0.6, 1: 0.4}, penalty='l1',\n",
       "                    solver='liblinear'),\n",
       " SVC(C=0.0001, class_weight={0: 0.5, 1: 0.5}, gamma=0.001, kernel='linear',\n",
       "     probability=True),\n",
       " KNeighborsClassifier(leaf_size=10, n_neighbors=10),\n",
       " GaussianNB(var_smoothing=1.0),\n",
       " DecisionTreeClassifier(criterion='entropy', max_depth=2, max_features='log2',\n",
       "                        random_state=10),\n",
       " RandomForestClassifier(criterion='entropy', max_depth=2, max_features='log2',\n",
       "                        min_samples_leaf=5, n_estimators=6),\n",
       " AdaBoostClassifier(algorithm='SAMME', learning_rate=0.97, n_estimators=4),\n",
       " ExtraTreesClassifier(n_estimators=20),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.4,\n",
       "               enable_categorical=False, gamma=0.1, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.3, max_delta_step=0, max_depth=12,\n",
       "               min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None),\n",
       " GradientBoostingClassifier(criterion='mae', max_features='auto',\n",
       "                            min_samples_leaf=4, min_samples_split=5,\n",
       "                            n_estimators=10, subsample=0.85)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexityEvaluator:\n",
    "\n",
    "    def __init__(self, nrow_samples, ncol_samples):\n",
    "        self._nrow_samples = nrow_samples\n",
    "        self._ncol_samples = ncol_samples\n",
    "\n",
    "    def _time_samples(self, model, random_data_generator):\n",
    "        rows_list = []\n",
    "        for nrow in self._nrow_samples:\n",
    "            for ncol in self._ncol_samples:\n",
    "                train, labels = random_data_generator(nrow, ncol)\n",
    "\n",
    "                start_time = time.time()\n",
    "                model.fit(train, labels)\n",
    "                elapsed_time = time.time() - start_time\n",
    "\n",
    "                result = {\"N\": nrow, \"P\": ncol, \"Time\": elapsed_time}\n",
    "                rows_list.append(result)\n",
    "\n",
    "        return rows_list\n",
    "\n",
    "    def Run(self, model, random_data_generator):\n",
    "        data = pd.DataFrame(self._time_samples(model, random_data_generator))\n",
    "        print(data)\n",
    "        data = data.applymap(math.log)\n",
    "        linear_model = LinearRegression(fit_intercept=True)\n",
    "        linear_model.fit(data[[\"N\", \"P\"]], data[[\"Time\"]])\n",
    "        return linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_evaluator = ComplexityEvaluator(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-3d4f2eca6d65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassification_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplexity_evaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_data_classification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     print(names[i] + ' | ' + str(round(res[0], 2)) +\n\u001b[0;32m      5\u001b[0m           ' | ' + str(round(res[1], 2)))\n",
      "\u001b[1;32m<ipython-input-59-cf27d8420a84>\u001b[0m in \u001b[0;36mRun\u001b[1;34m(self, model, random_data_generator)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_data_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_time_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_data_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-cf27d8420a84>\u001b[0m in \u001b[0;36m_time_samples\u001b[1;34m(self, model, random_data_generator)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nrow_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mncol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ncol_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_data_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-52033fc64465>\u001b[0m in \u001b[0;36mrandom_data_classification\u001b[1;34m(n, p)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrandom_data_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.rand\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.random_sample\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.double_fill\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for model in classification_models:\n",
    "    res = complexity_evaluator.Run(model, random_data_classification)[0]\n",
    "    print(names[i] + ' | ' + str(round(res[0], 2)) +\n",
    "          ' | ' + str(round(res[1], 2)))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data_generator(n , p):\n",
    "    return np.random.rand(n , p) , np.random.rand(n , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data_classification(n, p):\n",
    "    return np.random.rand(n, p), np.random.binomial(1, 0.5, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
